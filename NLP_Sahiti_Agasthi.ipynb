{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": true
    },
    "colab": {
      "name": "NLP_CW2_Sahiti Agasthi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8H6ONauEgve",
        "colab_type": "text"
      },
      "source": [
        "##Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr7v7CMPuyTU",
        "colab_type": "text"
      },
      "source": [
        "### Download the IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-01T20:37:46.288265Z",
          "start_time": "2019-10-01T20:37:46.238605Z"
        },
        "id": "vj2pt9XeuyTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download reviews.txt and labels.txt from here: https://github.com/udacity/deep-learning/tree/master/sentiment-network\n",
        "\n",
        "def pretty_print_review_and_label(i):\n",
        "   print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")\n",
        "\n",
        "g = open('/content/drive/My Drive/NLP/Data/reviews.txt','r') # What we know!\n",
        "reviews = list(map(lambda x:x[:-1],g.readlines()))\n",
        "g.close()\n",
        "\n",
        "g = open('/content/drive/My Drive/NLP/Data/labels.txt','r') # What we WANT to know!\n",
        "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
        "g.close()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw3_o1nOuyTZ",
        "colab_type": "text"
      },
      "source": [
        "### Capturing Word Correlation in Input Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-01T20:38:39.840145Z",
          "start_time": "2019-10-01T20:38:39.803959Z"
        },
        "id": "IUrSwRN0uyTZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "019b775f-3430-485c-85c9-a5cc6c9e7673"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "onehots = {}\n",
        "onehots['cat'] = np.array([1,0,0,0])\n",
        "onehots['the'] = np.array([0,1,0,0])\n",
        "onehots['dog'] = np.array([0,0,1,0])\n",
        "onehots['sat'] = np.array([0,0,0,1])\n",
        "\n",
        "sentence = ['the','cat','sat']\n",
        "x = onehots[sentence[0]] + \\\n",
        "    onehots[sentence[1]] + \\\n",
        "    onehots[sentence[2]]\n",
        "\n",
        "print(\"Sent Encoding:\" + str(x))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sent Encoding:[1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8aTeHwBuyTd",
        "colab_type": "text"
      },
      "source": [
        "### Predicting Movie Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-01T20:41:28.915232Z",
          "start_time": "2019-10-01T20:41:27.868201Z"
        },
        "id": "q8rSwI7muyTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "f = open('/content/drive/My Drive/NLP/Data/reviews.txt')\n",
        "raw_reviews = f.readlines()\n",
        "f.close()\n",
        "\n",
        "f = open('/content/drive/My Drive/NLP/Data/labels.txt')\n",
        "raw_labels = f.readlines()\n",
        "f.close()\n",
        "\n",
        "tokens = list(map(lambda x:set(x.split(\" \")),raw_reviews))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-01T20:58:56.004955Z",
          "start_time": "2019-10-01T20:58:55.997201Z"
        },
        "id": "jTOyB7oUuyTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## tokens is a list of sets "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-01T21:07:23.397597Z",
          "start_time": "2019-10-01T21:07:22.379480Z"
        },
        "id": "c0w9eYYcuyTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()\n",
        "for sent in tokens:\n",
        "    for word in sent:\n",
        "        if(len(word)>0):\n",
        "            vocab.add(word)\n",
        "vocab = list(vocab)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-01T21:08:24.406953Z",
          "start_time": "2019-10-01T21:08:24.357526Z"
        },
        "id": "EpUlXgHCuyTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2index = {}\n",
        "for i,word in enumerate(vocab):\n",
        "    word2index[word]=i"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCIMNNhVHt4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86934778-11d9-458e-af90-28955a55f7cd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7c2OmTSHbDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8106b8ce-1be2-4156-cef6-f716d2011aba"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-01T21:10:37.808080Z",
          "start_time": "2019-10-01T21:10:36.385061Z"
        },
        "id": "nri_9-YLuyTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dataset = list()\n",
        "for sent in tokens:\n",
        "    sent_indices = list()\n",
        "    for word in sent:\n",
        "        try:\n",
        "            sent_indices.append(word2index[word])\n",
        "        except:\n",
        "            \"\"\n",
        "    input_dataset.append(list(set(sent_indices)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWhf_7jtuyTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_dataset = list()\n",
        "for label in raw_labels:\n",
        "    if label == 'positive\\n':\n",
        "        target_dataset.append(1)\n",
        "    else:\n",
        "        target_dataset.append(0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKK4_GvYvywg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f2dbbdc-f78c-4724-8a6d-f878060b944d"
      },
      "source": [
        "# upload model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf8o1-Q7JA47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0c2ac102-eba5-42de-aebb-0ba74874475a"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from numpy import tensordot\n",
        "np.random.seed(1)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1/(1 + torch.exp(-x))\n",
        "\n",
        "alpha, iterations = (0.00008, 3)\n",
        "hidden_size = 50\n",
        "\n",
        "weights_0_1 = 0.2*torch.randn((len(vocab),hidden_size)) - 0.1\n",
        "weights_1_2 = 0.2*torch.randn((hidden_size,1)) - 0.1\n",
        "\n",
        "correct,total = (0,0)\n",
        "for iter in range(iterations):\n",
        "    \n",
        "    # train on first 21,000\n",
        "    for i in range(len(input_dataset)-4000):\n",
        "     \n",
        "        x,y = (input_dataset[i],target_dataset[i])\n",
        "        layer_1 = sigmoid(torch.sum(weights_0_1[x],axis=0)) #embed + sigmoid\n",
        "        layer_2 = sigmoid(torch.matmul(layer_1,weights_1_2))  # linear + softmax\n",
        "\n",
        "        layer_2_delta = layer_2 - y # compare pred with truth\n",
        "        layer_1_delta = sigmoid(torch.matmul(layer_2_delta,weights_1_2.T)) #backprop\n",
        "\n",
        "        weights_0_1[x] -= layer_1_delta * alpha\n",
        "        weights_1_2 -= torch.ger(layer_1,layer_2_delta) * alpha\n",
        "\n",
        "        if(torch.abs(layer_2_delta) < 0.5000001):\n",
        "            correct += 1\n",
        "        total += 1\n",
        "        if(i % 10 == 9):\n",
        "            progress = str(i/float(len(input_dataset)))\n",
        "            sys.stdout.write('\\rIter:'+str(iter)\\\n",
        "                             +' Progress:'+progress[2:4]\\\n",
        "                             +'.'+progress[4:6]\\\n",
        "                             +'% Training Accuracy:'\\\n",
        "                             + str(correct/float(total)) + '%')\n",
        "    print()\n",
        "correct,total = (0,0)\n",
        "for i in range(len(input_dataset)-4000,len(input_dataset)):\n",
        "\n",
        "    x = input_dataset[i]\n",
        "    y = target_dataset[i]\n",
        "\n",
        "    layer_1 = sigmoid(torch.sum(weights_0_1[x],axis=0))\n",
        "    layer_2 = sigmoid(torch.matmul(layer_1,weights_1_2))\n",
        "    \n",
        "    if(torch.abs(layer_2 - y) < 0.5000001):\n",
        "        correct += 1\n",
        "    total += 1\n",
        "print(\"Test Accuracy:\" + str(correct / float(total)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter:0 Progress:83.99% Training Accuracy:0.8424285714285714%\n",
            "Iter:1 Progress:83.99% Training Accuracy:0.9191904761904762%\n",
            "Iter:2 Progress:83.99% Training Accuracy:0.946031746031746%\n",
            "Test Accuracy:0.99975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzwAaN0S7F8d",
        "colab_type": "text"
      },
      "source": [
        "##Question 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1S9RcgTLdJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "n_input, n_hidden, n_output = 2, 2, 1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns4fFmuoM8SU",
        "colab_type": "text"
      },
      "source": [
        "###Parameter initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcjBMoiILfNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## initialize tensor for inputs, and outputs \n",
        "inp = [1,2]\n",
        "inp = torch.FloatTensor(inp)\n",
        "oup = torch.randn((1, n_output))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUX-pHKVWZ0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = ([[0, 0],\n",
        "      [0, 0]])\n",
        "w1= torch.FloatTensor(w1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyTV4pHSRsCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2 = ([[0],\n",
        "       [0]])\n",
        "w2= torch.FloatTensor(w2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWUIkDuJNIP5",
        "colab_type": "text"
      },
      "source": [
        "###Forward Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ0VFAQ-Lur9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## sigmoid activation function using pytorch\n",
        "def sigmoid_activation(z):\n",
        "    return 1 / (1 + torch.exp(-z))\n",
        "\n",
        "## activation of hidden layer \n",
        "z1 = torch.matmul(inp, w1) \n",
        "a1 = sigmoid_activation(z1)\n",
        "\n",
        "## output of final layer \n",
        "# we are not considering activation function of output layer\n",
        "output = torch.matmul(a1, w2) "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp680ILuNN4i",
        "colab_type": "text"
      },
      "source": [
        "###Loss Computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXiOBLfuDkgy",
        "colab_type": "text"
      },
      "source": [
        "###Taking 'Mean Square Error (MSE)' as loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_soOBPidNNEp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e5c49b4-ed3b-4475-ca81-dbff1339718d"
      },
      "source": [
        "l = (oup - output)**2\n",
        "loss = l/2\n",
        "loss"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2008]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-o95PRnNTnf",
        "colab_type": "text"
      },
      "source": [
        "###Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzCFfKntMO4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## function to calculate the derivative of activation\n",
        "def sigmoid_delta(m):\n",
        "  return m * (1 - m)\n",
        "\n",
        "## compute derivative of error terms\n",
        "delta_hidden = sigmoid_delta(a1)\n",
        "\n",
        "## backpass the changes to previous layers \n",
        "loss_h = torch.matmul(loss, w2.T)\n",
        "d_hidn = loss_h * delta_hidden"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMLVObkK_wr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d0e61ae0-25a1-4d90-9fdc-9df7b1f218e8"
      },
      "source": [
        "inp_t=inp.view(-1,1)\n",
        "inp_t"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [2.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bklNWGzNa42m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "05238348-0258-4cd4-a386-fb008df925c9"
      },
      "source": [
        "a1_t=a1.view(-1,1)\n",
        "a1_t"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5000],\n",
              "        [0.5000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj2cFizSNYP1",
        "colab_type": "text"
      },
      "source": [
        "###Updating the Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFwRTE_pNXjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "7f9ef55c-9f09-4be4-9255-841c50a609d0"
      },
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "w2 -= torch.matmul(a1_t, loss) * learning_rate\n",
        "w1 -=  torch.matmul(inp_t,d_hidn) * learning_rate\n",
        "\n",
        "print (\"epoch 1 :\")\n",
        "print (\"Output :\" + str(output))\n",
        "print (\"Predicted output :\" + str(oup))\n",
        "print (\"Loss :\"  + str(loss))\n",
        "print (\"W1 :\" + str(w1))\n",
        "print (\"W2 :\" + str(w2))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 :\n",
            "Output :tensor([0.])\n",
            "Predicted output :tensor([[-0.6337]])\n",
            "Loss :tensor([[0.2008]])\n",
            "W1 :tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "W2 :tensor([[-0.0100],\n",
            "        [-0.0100]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gViQPL8dbVBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d76295b9-58f1-46d7-e43d-f64b870503e0"
      },
      "source": [
        "## sigmoid activation function using pytorch\n",
        "def sigmoid_activation(z):\n",
        "    return 1 / (1 + torch.exp(-z))\n",
        "\n",
        " ## function to calculate the derivative of activation\n",
        "def sigmoid_delta(m):\n",
        "  return m * (1 - m)\n",
        "\n",
        "## activation of hidden layer \n",
        "z1 = torch.matmul(inp, w1) \n",
        "a1 = sigmoid_activation(z1)\n",
        "\n",
        "## output of final layer \n",
        "# we are not considering activation function of output layer\n",
        "output = torch.matmul(a1, w2)\n",
        "\n",
        "l = (oup - output)**2\n",
        "loss = l/2\n",
        "loss\n",
        "\n",
        "## compute derivative of error terms\n",
        "delta_hidden = sigmoid_delta(a1)\n",
        "\n",
        "## backpass the changes to previous layers \n",
        "loss_h = torch.matmul(loss, w2.T)\n",
        "d_hidn = loss_h * delta_hidden\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "w2 -= torch.matmul(a1_t, loss) * learning_rate\n",
        "w1 -=  torch.matmul(inp_t,d_hidn) * learning_rate\n",
        "\n",
        "print (\"epoch 2 :\")\n",
        "print (\"Output :\" + str(output))\n",
        "print (\"Predicted output :\" + str(oup))\n",
        "print (\"Loss :\"  + str(loss))\n",
        "print (\"W1 :\" + str(w1))\n",
        "print (\"W2 :\" + str(w2))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 2 :\n",
            "Output :tensor([-0.0100])\n",
            "Predicted output :tensor([[-0.6337]])\n",
            "Loss :tensor([[0.1945]])\n",
            "W1 :tensor([[4.8807e-05, 4.8807e-05],\n",
            "        [9.7614e-05, 9.7614e-05]])\n",
            "W2 :tensor([[-0.0198],\n",
            "        [-0.0198]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik6wxk1Z70X6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "ab50e290-8148-46fe-be42-f2dfd2d1328b"
      },
      "source": [
        "## sigmoid activation function using pytorch\n",
        "def sigmoid_activation(z):\n",
        "    return 1 / (1 + torch.exp(-z))\n",
        "\n",
        " ## function to calculate the derivative of activation\n",
        "def sigmoid_delta(m):\n",
        "  return m * (1 - m)\n",
        "\n",
        "## activation of hidden layer \n",
        "z1 = torch.matmul(inp, w1) \n",
        "a1 = sigmoid_activation(z1)\n",
        "\n",
        "## output of final layer \n",
        "# we are not considering activation function of output layer\n",
        "output = torch.matmul(a1, w2)\n",
        "\n",
        "l = (oup - output)**2\n",
        "loss = l/2\n",
        "loss\n",
        "\n",
        "## compute derivative of error terms\n",
        "delta_hidden = sigmoid_delta(a1)\n",
        "\n",
        "## backpass the changes to previous layers \n",
        "loss_h = torch.matmul(loss, w2.T)\n",
        "d_hidn = loss_h * delta_hidden\n",
        "\n",
        "learning_rate = 0.1\n",
        "\n",
        "w2 -= torch.matmul(a1_t, loss) * learning_rate\n",
        "w1 -=  torch.matmul(inp_t,d_hidn) * learning_rate\n",
        "\n",
        "print (\"epoch 3 :\")\n",
        "print (\"Output :\" + str(output))\n",
        "print (\"Predicted output :\" + str(oup))\n",
        "print (\"Loss :\"  + str(loss))\n",
        "print (\"W1 :\" + str(w1))\n",
        "print (\"W2 :\" + str(w2))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 3 :\n",
            "Output :tensor([-0.0198])\n",
            "Predicted output :tensor([[-0.6337]])\n",
            "Loss :tensor([[0.1885]])\n",
            "W1 :tensor([[0.0001, 0.0001],\n",
            "        [0.0003, 0.0003]])\n",
            "W2 :tensor([[-0.0292],\n",
            "        [-0.0292]])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}